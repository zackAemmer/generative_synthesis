{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "###### Build up fundamental model:\n",
    "-Test speeds vs traditional methods  \n",
    "-Energy distance test for distributions  \n",
    "-Check distributions of variables within households, compare to naive method w/borysov model somehow  \n",
    "-Test making epsilon the same distribution as the actual posteriors in the model\n",
    "\n",
    "###### Differentiate from the GenSynth paper:\n",
    "-Travel diaries  \n",
    "-Method/heuristic/rules for checking large number of attributes  \n",
    "-New models; Disentangled VAE/GAN  \n",
    "-Model population changes over time RNN  \n",
    "-Behavioral variables  \n",
    "\n",
    "###### They suggest:\n",
    "-Incorporate RNN to generate trip chains (time, location, mode, purpose)  \n",
    "-Use GAN/other method to generate less inconsistencies  \n",
    "-Address next stage of re-sampling to get future populations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each input to training the model is a person's daily trip diary\n",
    "# Inputs; day of week, characteristics of person/hh\n",
    "# Outputs; trip purpose, mode, duration, distance\n",
    "# How to include Time of Day?\n",
    "# Timesteps could either be hours in the day, or trips in a chain?\n",
    "    # If a timestep is a trip, add the time of departure to the output variables\n",
    "    \n",
    "# Timestep is a trip\n",
    "# Output of each timestep is departure time, duration, distance, mode, and purpose (y)\n",
    "# Input of each timestep is person/hh variables, day of week, and previous timestep info (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as skpre\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the persons PUMS dataset for WA state\n",
    "t_df = pd.read_csv('data/NHTS/nhts_survey/trippub.csv')\n",
    "p_df = pd.read_csv('data/NHTS/nhts_survey/perpub.csv')\n",
    "h_df = pd.read_csv('data/NHTS/nhts_survey/hhpub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Variables and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset n=923572 pre-cleaning\n",
      "Dataset n=405590 post-cleaning\n"
     ]
    }
   ],
   "source": [
    "# Filter to desired variables (numeric then categorical)\n",
    "#TRIPPURP = simplified why/from\n",
    "nhts_data_t = t_df[['TDCASEID','HOUSEID','PERSONID','TDAYDATE','TRAVDAY','TDTRPNUM','STRTTIME','TRVLCMIN','TRPMILES','TRPTRANS','WHYFROM','WHYTO']]\n",
    "nhts_data_p = p_df[['HOUSEID','PERSONID','R_AGE','TIMETOWK','EDUC','R_SEX','OCCAT']]\n",
    "nhts_data_h = h_df[['HOUSEID','HHSIZE','HHFAMINC','HHVEHCNT']]\n",
    "del t_df\n",
    "del p_df\n",
    "del h_df\n",
    "nhts_data = pd.merge(nhts_data_t, nhts_data_h, on='HOUSEID', how='left')\n",
    "nhts_data = pd.merge(nhts_data, nhts_data_p, on=['HOUSEID', 'PERSONID'], how='left')\n",
    "\n",
    "# Give each set of daily trips a unique chain id (each will be an input to model)\n",
    "nhts_data['CHAINID'] = nhts_data.groupby(['TDAYDATE','HOUSEID','PERSONID']).ngroup().values\n",
    "nhts_data = nhts_data.drop(labels=['TDAYDATE','TDCASEID','HOUSEID','PERSONID'], axis=1)\n",
    "\n",
    "# Remove NA values and check n before/after\n",
    "print(f\"Dataset n={len(nhts_data)} pre-cleaning\")\n",
    "nan_indices = list((nhts_data < 0).any(axis=1))\n",
    "nan_ids = nhts_data[nan_indices][['CHAINID']].values.flatten()\n",
    "nhts_data = nhts_data[~(nhts_data['CHAINID'].isin(nan_ids))]\n",
    "print(f\"Dataset n={len(nhts_data)} post-cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only numeric variables, only dynamic variables\n",
    "nhts_data = nhts_data[['TRAVDAY','TDTRPNUM','STRTTIME','TRVLCMIN','TRPMILES','TRPTRANS','CHAINID']].copy()\n",
    "MANIFEST_DIM = nhts_data.values.shape[1]-1 # All except chainid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAVDAY</th>\n",
       "      <th>TDTRPNUM</th>\n",
       "      <th>STRTTIME</th>\n",
       "      <th>TRVLCMIN</th>\n",
       "      <th>TRPMILES</th>\n",
       "      <th>TRPTRANS</th>\n",
       "      <th>CHAINID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>120</td>\n",
       "      <td>84.004</td>\n",
       "      <td>6</td>\n",
       "      <td>46938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1800</td>\n",
       "      <td>150</td>\n",
       "      <td>81.628</td>\n",
       "      <td>6</td>\n",
       "      <td>46938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1115</td>\n",
       "      <td>15</td>\n",
       "      <td>8.017</td>\n",
       "      <td>6</td>\n",
       "      <td>46940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2330</td>\n",
       "      <td>10</td>\n",
       "      <td>8.017</td>\n",
       "      <td>6</td>\n",
       "      <td>46940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>15</td>\n",
       "      <td>3.395</td>\n",
       "      <td>4</td>\n",
       "      <td>24626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923567</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>810</td>\n",
       "      <td>27</td>\n",
       "      <td>1.168</td>\n",
       "      <td>1</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923568</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1320</td>\n",
       "      <td>8</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923569</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1415</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923570</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1820</td>\n",
       "      <td>25</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923571</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1848</td>\n",
       "      <td>7</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405590 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRAVDAY  TDTRPNUM  STRTTIME  TRVLCMIN  TRPMILES  TRPTRANS  CHAINID\n",
       "2             2         1       700       120    84.004         6    46938\n",
       "3             2         2      1800       150    81.628         6    46938\n",
       "6             5         1      1115        15     8.017         6    46940\n",
       "7             5         2      2330        10     8.017         6    46940\n",
       "8             5         1       550        15     3.395         4    24626\n",
       "...         ...       ...       ...       ...       ...       ...      ...\n",
       "923567        3         1       810        27     1.168         1    93638\n",
       "923568        3         2      1320         8     0.238         1    93638\n",
       "923569        3         3      1415         5     0.238         1    93638\n",
       "923570        3         4      1820        25     0.867         1    93638\n",
       "923571        3         5      1848         7     0.325         1    93638\n",
       "\n",
       "[405590 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data that will be fed into model\n",
    "model_data_df = nhts_data\n",
    "model_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15040\n",
      "4448\n",
      "467\n"
     ]
    }
   ],
   "source": [
    "# Remove chains that have more than 5 trips in them\n",
    "MAX_TIMESTEPS = 5  # Make sure to add 1 when generating the chain data (1 gets removed in training)\n",
    "long_chains = model_data_df[model_data_df['TDTRPNUM'] > MAX_TIMESTEPS+1][['CHAINID']].values.flatten()\n",
    "model_data_df = model_data_df[~model_data_df['CHAINID'].isin(long_chains)]\n",
    "print(len(pd.unique(long_chains)))\n",
    "\n",
    "## Remove outliers\n",
    "# Filter model data into train/test data\n",
    "chain_ids = pd.unique(model_data_df['CHAINID'])\n",
    "train_idx = round(len(chain_ids)*.9)\n",
    "train_ids = chain_ids[0:train_idx]\n",
    "test_ids = chain_ids[train_idx:len(chain_ids)]\n",
    "train_data_df = model_data_df[model_data_df['CHAINID'].isin(train_ids)]\n",
    "test_data_df = model_data_df[model_data_df['CHAINID'].isin(test_ids)]\n",
    "\n",
    "# Standardize the input data from -1 to 1 for numerical variables, remove outliers (x > 3 SD)\n",
    "scaler_train = skpre.StandardScaler()\n",
    "scaler_test = skpre.StandardScaler()\n",
    "train_data = scaler_train.fit_transform(train_data_df.values)\n",
    "test_data = scaler_test.fit_transform(test_data_df.values)\n",
    "\n",
    "# Remove outliers from dataset once for training data...\n",
    "outlier_indices = np.where(np.any(train_data > 3, axis=1))[0]\n",
    "outlier_chains = train_data_df.iloc[outlier_indices,:][['CHAINID']].values.flatten()\n",
    "train_data_df = train_data_df[~train_data_df['CHAINID'].isin(outlier_chains)]\n",
    "print(len(outlier_chains))\n",
    "\n",
    "# ...and again for testing data (keep the scalers separate)\n",
    "outlier_indices = np.where(np.any(test_data > 3, axis=1))[0]\n",
    "outlier_chains = test_data_df.iloc[outlier_indices,:][['CHAINID']].values.flatten()\n",
    "test_data_df = test_data_df[~test_data_df['CHAINID'].isin(outlier_chains)]\n",
    "print(len(outlier_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the model data to a format that is usable by tensorflow: shape = (#samples, timestep size, #features)\n",
    "train_samples_x = []\n",
    "train_samples_y = []\n",
    "chain_ids = pd.unique(train_data_df['CHAINID'])\n",
    "train_data_df.iloc[:,:MANIFEST_DIM] = scaler_train.fit_transform(train_data_df.iloc[:,:MANIFEST_DIM].values)  # Scale all variables except Chainid\n",
    "\n",
    "# This could be faster\n",
    "for chain_id in chain_ids:\n",
    "    data = train_data_df[train_data_df['CHAINID'] == chain_id].values.transpose()\n",
    "    data = keras.preprocessing.sequence.pad_sequences(data, MAX_TIMESTEPS+1, padding='pre').transpose()\n",
    "    data = data[:,:-1]  # Remove Chainid\n",
    "    data_offset = data[1:,:]  # Validation data is offset by 1 timestep\n",
    "    data = data[:-1,:]  # Remove the final timestep from input data (no validation for it)\n",
    "    train_samples_x.append(data)\n",
    "    train_samples_y.append(data_offset)\n",
    "\n",
    "# Dimensions are: (samples, timesteps, features)\n",
    "train_data_x = np.array(train_samples_x)\n",
    "train_data_y = np.array(train_samples_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the model data to a format that is usable by tensorflow: shape = (#samples, timestep size, #features)\n",
    "# TODO: Make sure this is working correctly\n",
    "test_samples_x = []\n",
    "test_samples_y = []\n",
    "chain_ids = pd.unique(test_data_df['CHAINID'])\n",
    "test_data_df.iloc[:,:MANIFEST_DIM] = scaler_test.fit_transform(test_data_df.iloc[:,:MANIFEST_DIM].values)  # Scale all variables except Chainid\n",
    "\n",
    "# This could be faster\n",
    "for chain_id in chain_ids:\n",
    "    data = test_data_df[test_data_df['CHAINID'] == chain_id].values.transpose()\n",
    "    data = keras.preprocessing.sequence.pad_sequences(data, MAX_TIMESTEPS+1, padding='pre').transpose()\n",
    "    data = data[:,:-1]  # Remove Chainid\n",
    "    data_offset = data[1:,:]  # Validation data is offset by 1 timestep\n",
    "    data = data[:-1,:]  # Remove the final timestep from input data (no validation for it)\n",
    "    test_samples_x.append(data)\n",
    "    test_samples_y.append(data_offset)\n",
    "\n",
    "# Dimensions are: (samples, timesteps, features)\n",
    "test_data_x = np.array(test_samples_x)\n",
    "test_data_y = np.array(test_samples_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69288, 5, 6)\n",
      "(69288, 5, 6)\n",
      "(7733, 5, 6)\n",
      "(7733, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "# shape = (#samples, timestep size, #features)\n",
    "print(train_data_x.shape)\n",
    "print(train_data_y.shape)\n",
    "print(test_data_x.shape)\n",
    "print(test_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters and Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestep is a trip\n",
    "# Output of each timestep is departure time, duration, distance, mode, and purpose (dynamic)\n",
    "# Input of each timestep is person/hh variables, day of week, and previous timestep info (static + dynamic)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5\n",
    "LEARN_RATE = 0.01\n",
    "RHO = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 5, 6)]            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5, 10)             70        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 10)             840       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5, 6)              66        \n",
      "=================================================================\n",
      "Total params: 976\n",
      "Trainable params: 976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# I should try embedding trips as a classification => one for each mode, orig/dest purpose\n",
    "# How to do dist/time/other? Separate variables?\n",
    "\n",
    "# LSTM layer requires inputs to be 3D tensor with shape [batch, timesteps, feature]\n",
    "inputs = keras.Input(shape=(MAX_TIMESTEPS, MANIFEST_DIM))\n",
    "dense = layers.Dense(10, activation=\"tanh\")(inputs)\n",
    "lstm = layers.LSTM(10, activation=\"tanh\", return_sequences=True)(dense)\n",
    "outputs = layers.Dense(MANIFEST_DIM, activation=\"tanh\")(lstm)\n",
    "\n",
    "# Define and print model\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"./model_checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "691/693 [============================>.] - ETA: 0s - loss: 0.2354\n",
      "Epoch 00001: loss improved from inf to 0.23541, saving model to ./model_checkpoints/weights-improvement-01-0.2354.hdf5\n",
      "693/693 [==============================] - 4s 5ms/step - loss: 0.2354\n",
      "Epoch 2/5\n",
      "691/693 [============================>.] - ETA: 0s - loss: 0.2256\n",
      "Epoch 00002: loss improved from 0.23541 to 0.22558, saving model to ./model_checkpoints/weights-improvement-02-0.2256.hdf5\n",
      "693/693 [==============================] - 4s 5ms/step - loss: 0.2256\n",
      "Epoch 3/5\n",
      "686/693 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 00003: loss improved from 0.22558 to 0.22385, saving model to ./model_checkpoints/weights-improvement-03-0.2239.hdf5\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2239\n",
      "Epoch 4/5\n",
      "682/693 [============================>.] - ETA: 0s - loss: 0.2228\n",
      "Epoch 00004: loss improved from 0.22385 to 0.22264, saving model to ./model_checkpoints/weights-improvement-04-0.2226.hdf5\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2226\n",
      "Epoch 5/5\n",
      "687/693 [============================>.] - ETA: 0s - loss: 0.2220\n",
      "Epoch 00005: loss improved from 0.22264 to 0.22192, saving model to ./model_checkpoints/weights-improvement-05-0.2219.hdf5\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.2219\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.RMSprop(learning_rate=LEARN_RATE, rho=RHO))\n",
    "history = model.fit(train_data_x, train_data_y, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot model loss/training progress\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Training History\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"total\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from the best result of the training\n",
    "filename = \"./model_checkpoints/weights-improvement-05-0.2219.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.RMSprop(learning_rate=LEARN_RATE, rho=RHO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 trip chains, each with MAXTIMESTEPS timesteps (each represents 1 day for 1 individual)\n",
    "NUM_CHAINS = 10\n",
    "result_chains = []\n",
    "\n",
    "for i in range(NUM_CHAINS):\n",
    "    seed = np.random.rand(MAX_TIMESTEPS, MANIFEST_DIM)\n",
    "    #seed = np.zeros((MAX_TIMESTEPS, MANIFEST_DIM))  # Generate either random, or zero-based seed for first trip\n",
    "    seed = np.reshape(seed, (1, MAX_TIMESTEPS, MANIFEST_DIM))\n",
    "\n",
    "    # Make first prediction to start from\n",
    "    prediction = model.predict(seed, verbose=0)\n",
    "    result = prediction\n",
    "\n",
    "    # After each prediction, add the prediction to the results and re-predict the remaining timesteps from the results\n",
    "    for j in range(1, MAX_TIMESTEPS):\n",
    "        prediction = model.predict(result, verbose=0)\n",
    "        result[:,j:,:] = prediction[:,j:,:]\n",
    "    result_chains.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,7) (6,) (6,7) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4c0d8aa1dddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Scale the results back to real values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msynthetic_chains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMANIFEST_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthetic_chains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMANIFEST_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    843\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,7) (6,) (6,7) "
     ]
    }
   ],
   "source": [
    "# Get the data in the same dimensions as the input data\n",
    "synthetic_chains = np.array(result_chains).reshape(NUM_CHAINS, MAX_TIMESTEPS, MANIFEST_DIM)\n",
    "\n",
    "# Assign a trip chain id to each synthetic chain\n",
    "chain_ids = []\n",
    "# Get np array of chain ids to append, must be same dims as the synthetic results\n",
    "for i in range(NUM_CHAINS):\n",
    "    to_add = np.zeros(MAX_TIMESTEPS) + i\n",
    "    to_add = np.reshape(to_add, (MAX_TIMESTEPS, 1))\n",
    "    chain_ids.append(to_add)\n",
    "chain_ids = np.array(chain_ids)\n",
    "synthetic_chains = np.append(synthetic_chains, chain_ids, axis=2).reshape((NUM_CHAINS*MAX_TIMESTEPS), MANIFEST_DIM+1)\n",
    "\n",
    "# Scale the results back to real values\n",
    "synthetic_chains[:MANIFEST_DIM,:] = scaler_train.inverse_transform(synthetic_chains[:MANIFEST_DIM,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MANIFEST_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.95438701e-01,  8.34055364e-01,  3.96876335e-02,\n",
       "         5.74612198e-03, -3.21390890e-02,  4.36797470e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 3.31206739e-01,  9.91451859e-01,  8.14472497e-01,\n",
       "        -1.44440308e-01, -2.79775411e-01,  5.94668686e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 3.56876969e-01,  9.97133851e-01, -1.37743261e-03,\n",
       "        -2.82231301e-01, -4.07551140e-01,  7.80320585e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 3.67349029e-01,  9.98305976e-01,  9.19289827e-01,\n",
       "        -3.42471302e-01, -4.51612890e-01,  7.40068555e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 3.90197396e-01,  9.98731375e-01,  9.63475823e-01,\n",
       "        -3.66345555e-01, -3.85327488e-01,  5.34668863e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 5.76205850e-01,  4.81209785e-01,  6.34437144e-01,\n",
       "         2.16421828e-01,  2.90794134e-01,  4.43634808e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 3.78661990e-01,  9.92868841e-01,  5.28948188e-01,\n",
       "         1.65907502e-01,  5.03748238e-01,  7.35679507e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 3.44235152e-01,  9.95766997e-01,  9.85165060e-01,\n",
       "        -1.59061939e-01,  1.13331802e-01,  3.19657713e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 2.33635947e-01,  9.98141170e-01,  9.17674839e-01,\n",
       "         1.49065405e-01,  7.02293217e-01,  1.86625406e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.31457418e-01,  9.98360872e-01,  9.90234733e-01,\n",
       "        -2.95616180e-01,  1.86954383e-02, -8.14088657e-02,\n",
       "         1.00000000e+00],\n",
       "       [ 2.98264533e-01,  9.38161671e-01,  6.77337945e-01,\n",
       "         4.15639251e-01,  7.28108525e-01,  1.87498033e-01,\n",
       "         2.00000000e+00],\n",
       "       [ 1.84009627e-01,  9.82473373e-01,  9.01097775e-01,\n",
       "         3.28813374e-01,  8.16651821e-01,  2.42089499e-02,\n",
       "         2.00000000e+00],\n",
       "       [ 1.12743229e-01,  9.92127717e-01,  9.67510283e-01,\n",
       "        -1.65479556e-01,  3.21610391e-01, -1.63668841e-01,\n",
       "         2.00000000e+00],\n",
       "       [ 1.26707584e-01,  9.95010793e-01,  9.84893501e-01,\n",
       "        -3.99917215e-01, -1.91959679e-01, -1.18175544e-01,\n",
       "         2.00000000e+00],\n",
       "       [ 1.22361809e-01,  9.96697366e-01,  9.84116912e-01,\n",
       "        -4.72156554e-01, -3.49198699e-01, -4.90964763e-02,\n",
       "         2.00000000e+00],\n",
       "       [ 2.87239015e-01,  9.51074719e-01,  2.34013855e-01,\n",
       "         7.17783689e-01,  9.41743970e-01,  2.22118407e-01,\n",
       "         3.00000000e+00],\n",
       "       [ 3.96306664e-02,  9.82293069e-01,  8.88786435e-01,\n",
       "         2.29658097e-01,  6.60881639e-01, -1.46610409e-01,\n",
       "         3.00000000e+00],\n",
       "       [ 1.15179212e-03,  9.89630640e-01,  9.66056705e-01,\n",
       "        -1.28827378e-01,  3.10597241e-01, -2.43880793e-01,\n",
       "         3.00000000e+00],\n",
       "       [-3.93829048e-02,  9.93836641e-01,  9.77546334e-01,\n",
       "        -2.63882816e-01,  7.18721673e-02, -1.97372168e-01,\n",
       "         3.00000000e+00],\n",
       "       [-1.90657511e-01,  9.96282995e-01,  9.80849385e-01,\n",
       "        -4.36850131e-01, -3.34020764e-01, -1.42709449e-01,\n",
       "         3.00000000e+00],\n",
       "       [ 3.11205268e-01,  9.44844186e-01,  9.56851840e-02,\n",
       "         5.36604822e-01,  8.65287244e-01,  4.62655187e-01,\n",
       "         4.00000000e+00],\n",
       "       [ 1.00738704e-01,  9.84353900e-01,  4.54407603e-01,\n",
       "         4.01485443e-01,  8.70662630e-01,  5.25304340e-02,\n",
       "         4.00000000e+00],\n",
       "       [-1.44344214e-02,  9.91718590e-01,  9.52225626e-01,\n",
       "        -9.00877938e-02,  4.36227739e-01, -2.42941678e-01,\n",
       "         4.00000000e+00],\n",
       "       [-1.68583114e-02,  9.94404912e-01,  9.84437048e-01,\n",
       "        -3.67729545e-01, -1.01596415e-01, -1.76070496e-01,\n",
       "         4.00000000e+00],\n",
       "       [-1.17701307e-01,  9.96432126e-01,  9.84238803e-01,\n",
       "        -4.40453142e-01, -2.95260519e-01, -1.19180240e-01,\n",
       "         4.00000000e+00],\n",
       "       [ 4.22953486e-01,  9.21493292e-01,  4.57469076e-01,\n",
       "         1.31824136e-01,  2.65180260e-01,  4.31063354e-01,\n",
       "         5.00000000e+00],\n",
       "       [ 2.86246926e-01,  9.89479899e-01,  1.70067802e-01,\n",
       "         2.40185913e-02,  1.76174372e-01,  6.42449737e-01,\n",
       "         5.00000000e+00],\n",
       "       [ 2.98124313e-01,  9.96239901e-01,  9.32075858e-01,\n",
       "        -1.87233031e-01, -9.98514146e-02,  5.48605978e-01,\n",
       "         5.00000000e+00],\n",
       "       [ 3.03531170e-01,  9.97753203e-01,  9.65219080e-01,\n",
       "        -3.46596777e-01, -3.10782582e-01,  3.10246468e-01,\n",
       "         5.00000000e+00],\n",
       "       [ 2.58468598e-01,  9.98309195e-01,  9.73075449e-01,\n",
       "        -3.68000597e-01, -3.03126335e-01,  1.93159163e-01,\n",
       "         5.00000000e+00],\n",
       "       [ 5.16593397e-01,  9.15835381e-01,  7.91292116e-02,\n",
       "         2.13165283e-01,  6.78230584e-01,  8.60107601e-01,\n",
       "         6.00000000e+00],\n",
       "       [ 2.55882442e-01,  9.85953331e-01,  7.77866006e-01,\n",
       "         2.84155190e-01,  7.56841063e-01,  4.04910773e-01,\n",
       "         6.00000000e+00],\n",
       "       [ 1.76391080e-01,  9.94101346e-01,  9.26578879e-01,\n",
       "        -1.63844392e-01,  3.03769171e-01,  8.42895359e-02,\n",
       "         6.00000000e+00],\n",
       "       [ 2.09379032e-01,  9.96049702e-01,  9.82952118e-01,\n",
       "        -3.37476164e-01, -3.61089110e-02, -2.01485623e-02,\n",
       "         6.00000000e+00],\n",
       "       [ 9.98808965e-02,  9.97329593e-01,  9.85195398e-01,\n",
       "        -4.56687927e-01, -3.01621825e-01, -6.31508306e-02,\n",
       "         6.00000000e+00],\n",
       "       [ 3.03786993e-01,  9.31988239e-01,  3.54931176e-01,\n",
       "         7.09591508e-01,  9.33382869e-01,  4.66901720e-01,\n",
       "         7.00000000e+00],\n",
       "       [ 1.36912510e-01,  9.84741330e-01,  4.38754648e-01,\n",
       "         3.12243700e-01,  8.67485523e-01,  1.61829591e-01,\n",
       "         7.00000000e+00],\n",
       "       [-1.72838308e-02,  9.91063416e-01,  9.56559360e-01,\n",
       "        -7.67121539e-02,  4.34263200e-01, -2.24284992e-01,\n",
       "         7.00000000e+00],\n",
       "       [-4.72674705e-03,  9.94212091e-01,  9.84999299e-01,\n",
       "        -3.13673407e-01,  3.39003764e-02, -1.72863126e-01,\n",
       "         7.00000000e+00],\n",
       "       [-8.10225680e-02,  9.96336937e-01,  9.85891163e-01,\n",
       "        -4.64266807e-01, -3.32376808e-01, -1.07240506e-01,\n",
       "         7.00000000e+00],\n",
       "       [ 2.52025306e-01,  9.28421199e-01,  4.27483348e-03,\n",
       "         4.54755753e-01,  7.32501984e-01,  5.92062175e-01,\n",
       "         8.00000000e+00],\n",
       "       [ 1.60675749e-01,  9.84370589e-01,  7.01341569e-01,\n",
       "         3.08610618e-01,  8.01980734e-01,  1.73278093e-01,\n",
       "         8.00000000e+00],\n",
       "       [ 8.30200016e-02,  9.92442548e-01,  9.63749766e-01,\n",
       "        -1.73206061e-01,  2.74629086e-01, -1.38922632e-01,\n",
       "         8.00000000e+00],\n",
       "       [ 1.26995280e-01,  9.94988024e-01,  9.78048205e-01,\n",
       "        -3.49070907e-01, -5.64675927e-02, -8.12821537e-02,\n",
       "         8.00000000e+00],\n",
       "       [-1.58924147e-01,  9.96797621e-01,  9.81865942e-01,\n",
       "        -2.43273377e-01,  1.54064700e-01, -1.96531743e-01,\n",
       "         8.00000000e+00],\n",
       "       [ 2.85313010e-01,  9.51522708e-01,  2.10775241e-01,\n",
       "         6.99015975e-01,  9.35944736e-01,  3.88376355e-01,\n",
       "         9.00000000e+00],\n",
       "       [ 8.30151886e-02,  9.83558059e-01,  7.05774903e-01,\n",
       "         2.92480707e-01,  7.68827260e-01,  1.77374762e-02,\n",
       "         9.00000000e+00],\n",
       "       [ 1.92776341e-02,  9.90410388e-01,  9.68693912e-01,\n",
       "        -8.90186355e-02,  4.01357502e-01, -2.12138042e-01,\n",
       "         9.00000000e+00],\n",
       "       [ 2.66527049e-02,  9.94112909e-01,  9.83351171e-01,\n",
       "        -3.57119441e-01, -6.40635788e-02, -1.60496920e-01,\n",
       "         9.00000000e+00],\n",
       "       [ 1.78178947e-03,  9.96199071e-01,  9.84035671e-01,\n",
       "        -4.47714508e-01, -2.87132323e-01, -9.46649462e-02,\n",
       "         9.00000000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_chains[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "synthetic_trips_df = pd.DataFrame(synthetic_chains)\n",
    "synthetic_trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict fewer than 1,000 characters as output for a given seed.\n",
    "# Remove all punctuation from the source text, and therefore from the modelsâ€™ vocabulary.\n",
    "# Try a one hot encoded for the input sequences.\n",
    "# Train the model on padded sentences rather than random sequences of characters.\n",
    "# Increase the number of training epochs to 100 or many hundreds.\n",
    "# Add dropout to the visible input layer and consider tuning the dropout percentage.\n",
    "# Tune the batch size, try a batch size of 1 as a (very slow) baseline and larger sizes from there.\n",
    "# Add more memory units to the layers and/or more layers.\n",
    "# Experiment with scale factors (temperature) when interpreting the prediction probabilities.\n",
    "# Change the LSTM layers to be â€œstatefulâ€ to maintain state across batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
